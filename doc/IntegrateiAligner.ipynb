{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cite_corpus_reader.reader import CapitainCorpusReader, AncientGreekPunktVar\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "import cltk\n",
    "import os\n",
    "from cltk.corpus.utils.formatter import cltk_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iAligner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install `iAligner`,\n",
    "* download the latest release from the [github repo](https://github.com/OpenGreekAndLatin/ILA_python.git)\n",
    "* unzip the downloaded file\n",
    "* cd into the unzipped directory\n",
    "* run: `python setup.py install`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iAlignment.iAligner import iAligner\n",
    "from iAlignment.Viewer import Viewer\n",
    "from iAlignment.MultipleAligner import MultipleAligner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the CaptainReader and iAligner play together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iAligner expects the texts to be compared to be chunked into comparable units. In the visualization, these groups are visualized as $n$ parallel blocks, where the tokens are aligned. For prose texts, it makes sense to identify the sentence as the basic unit to chunk and compare the texts. For poetry, we may still align editions sentence by sentence or line by line. For this second approach, a CapitainCorpusReader is perhaps an overkill, but you can use it nonetheless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prose texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these few lines of codes we see how we can take two (or more!) capitain-compliant editions of Greek texts and compare them. As an example, we'll use two editions of Aristotle's *Analytica Priora*, that of Bekker and of Ross."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root of the two folders: Perseus Texts and First1kGreek\n",
    "fist1kroot = os.path.expanduser(\"~/cltk_data/greek/text/greek_text_first1kgreek/data\")\n",
    "perseusroot = os.path.expanduser(\"~/cltk_data/greek/text/canonical-greekLit-master/data\")\n",
    "\n",
    "arist_root = os.path.join(fist1kroot, \"tlg0086\")\n",
    "ar_an1_files = [\"tlg001/tlg0086.tlg001.1st1K-grc1.xml\", \"tlg001/tlg0086.tlg001.1st1K-grc2.xml\"]\n",
    "bekker,ross = ar_an1_files\n",
    "ar_an1 = CapitainCorpusReader(arist_root, ar_an1_files) #sent_tokenizer=sent_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big are these two texts (in terms of nr. of words)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71019 68575\n"
     ]
    }
   ],
   "source": [
    "print(len(ar_an1.words(bekker)), len(ar_an1.words(ross)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said, we work sentence by sentence. Let's now grab the sentences that we'll compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_bekker = ar_an1.sents(bekker)\n",
    "sents_ross = ar_an1.sents(ross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the first two sentences in a quick-and-dirty way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ΑΝΑΛΥΤΙΚΩΝ ΑΝΑΛΥΤΙΚΩΝ\n",
      "ΠΡΟΤΕΡΩΝ ΠΡΟΤΕΡΩΝ\n",
      "Α Α\n",
      ". .\n",
      "ΠΡΩΤΟΝ Πρῶτον\n",
      "εἰπεῖν εἰπεῖν\n",
      "περὶ περὶ\n",
      "τί τί\n",
      "καὶ καὶ\n",
      "τίνος τίνος\n",
      "ἐστὶν ἐστὶν\n",
      "ἡ ἡ\n",
      "σκέψις σκέψις\n",
      ", ,\n",
      "ὅτι ὅτι\n",
      "περὶ περὶ\n",
      "ἀπόδειξιν ἀπόδειξιν\n",
      "καὶ καὶ\n",
      "ἐπιστήμης ἐπιστήμης\n",
      "ἀποδεικτικῆς ἀποδεικτικῆς\n",
      "· ·\n"
     ]
    }
   ],
   "source": [
    "for b,r in zip(sents_bekker[0], sents_ross[0]) :\n",
    "    print(b,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look the same but don't be fooled! There's this dreaded problem of [unicode compatibility](http://docs.cltk.org/en/latest/greek.html#normalization) looming in the background...\n",
    "\n",
    "Obviously we want to solve that before we compare the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἐπιστήμης ἐπιστήμης\n",
      "False\n",
      "ή 8053 942\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(sents_bekker[0][-3], sents_ross[0][-3])\n",
    "print(sents_bekker[0][-3] == sents_ross[0][-3])\n",
    "print(sents_bekker[0][-3][5], ord(sents_bekker[0][-3][5]),\n",
    "     ord(sents_ross[0][-3][5]))\n",
    "\n",
    "print(cltk_normalize(sents_bekker[0][-3]) == sents_ross[0][-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the sentences to iAligner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iAligner provide some cool examples on how to use the intra-language-alignment tool to generate good html visualizations of the differences.\n",
    "\n",
    "Here's a code snippet of one of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "html=[]\n",
    "groups=content.split(\"\\n\\n\")\n",
    "for group in groups:\n",
    "    sentences=group.split(\"\\n\")\n",
    "    alignment = aligner.align(sentences)\n",
    "    html.append(viewer.mAlignmentToHtmlCode(alignment,sentences))\n",
    "    html.append(viewer.mAlignmentToTableCode(alignment, sentences))\n",
    "viewer.exportHtml(\"<br>\".join(html),\"OutputExample5-1.html\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a same routine to process the first 20 sentences of the *Analytics* by using the same logic. As the sentences returned by the corpus readers are lists of lists (tokens), we'll have to join them into a string (iAligner uses its own tokenizer): that's kind of redundant but it doesn't hurt so much...\n",
    "\n",
    "As we know that Bekker uses old unicode accented characters, we'll also normalize that using `cltk_normalize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = []\n",
    "aligner = MultipleAligner()\n",
    "viewer = Viewer()\n",
    "aligner.setOptions(1,0,1,1)\n",
    "\n",
    "for b_s,r_s in zip(sents_bekker[:20], sents_ross[:20]):\n",
    "    b_s = cltk_normalize(\" \".join(b_s))\n",
    "    r_s = cltk_normalize(\" \".join(r_s))\n",
    "    sentences = [b_s, r_s]\n",
    "    alignment = aligner.align(sentences)\n",
    "    html.append(viewer.mAlignmentToHtmlCode(alignment,sentences))\n",
    "    html.append(viewer.mAlignmentToTableCode(alignment, sentences))\n",
    "viewer.exportHtml(\"<br>\".join(html),\"AristotleExample.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_texts(text1, text2, outname, options = (1,0,1,1)):\n",
    "    \"\"\"Compare 2 texts using iAligner.\n",
    "    The two texts must be lists of chunks to be compared. \n",
    "    The chunks can be sentences or sections (e.g. lines), \n",
    "    they may hold lists of tokens or strings.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text1: list\n",
    "        text1 as a list of sections or senteces\n",
    "    text2: list\n",
    "        text2 as a list of sections or senteces\n",
    "    \"\"\"\n",
    "    html = []\n",
    "    aligner = MultipleAligner()\n",
    "    viewer = Viewer()\n",
    "    aligner.setOptions(*options)\n",
    "\n",
    "    for s1,s2 in zip(text1,text2):\n",
    "        if isinstance(s1, list):\n",
    "            assert isinstance(s2, list), \"Text1 and text2 must both be a list of lists or strings!\"\n",
    "            s1 = \" \".join(s1)\n",
    "            s2 = \" \".join(s2)\n",
    "        sentences = [s1, s2]\n",
    "        alignment = aligner.align(sentences)\n",
    "        html.append(viewer.mAlignmentToHtmlCode(alignment,sentences))\n",
    "        html.append(viewer.mAlignmentToTableCode(alignment, sentences))\n",
    "    viewer.exportHtml(\"<br>\".join(html),outname)\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now load two versions of a hotly debated tragedy: the *Suppliants* of Aeschylus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ζεὺς μὲν ἀφίκτωρ ἐπίδοι προφρόνως ',\n",
       " \"στόλον ἡμέτερον νάιον ἀρθέντ' \",\n",
       " 'ἀπὸ προστομίων λεπτοψαμάθων ',\n",
       " 'Νείλου. Δίαν δὲ λιποῦσαι ',\n",
       " 'χθόνα σύγχορτον Συρίᾳ φεύγομεν, ']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigd = CapitainCorpusReader(fist1kroot, \"tlg0085/tlg001/tlg0085.tlg001.opp-grc3.xml\")\n",
    "\n",
    "sigd_lines = [l.replace(\"᾽\", \"'\") for l in sigd.paras()]\n",
    "sigd_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ζεὺς μὲν ἀφίκτωρ ἐπίδοι προφρόνως ',\n",
       " \"στόλον ἡμέτερον νάιον ἀρθέντ' \",\n",
       " 'ἀπὸ προστομίων λεπτοψαμάθων ',\n",
       " 'Νείλου. Δίαν δὲ λιποῦσαι ',\n",
       " 'χθόνα σύγχορτον Συρίᾳ φεύγομεν, ']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smyth = CapitainCorpusReader(perseusroot, \"tlg0085/tlg001/tlg0085.tlg001.perseus-grc2.xml\")\n",
    "\n",
    "smyth_lines = [l.replace(\"ʼ\", \"'\") for l in smyth.paras()]\n",
    "smyth_lines = [l.replace(\"·\", \":\") for l in smyth_lines]\n",
    "smyth_lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we don't have any unicode problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smyth_lines[0][11] == sigd_lines[0][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = compare_texts(sigd_lines[:51], smyth_lines[:51], \"suppliants.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['τόποις', 'τόποις']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: testing iAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iAlignment.iAligner import iAligner\n",
    "from iAlignment.Viewer import Viewer\n",
    "\n",
    "#Example 1: simple alignment, align two sentences\n",
    "sentence1=\"And the earth was waste and void; and darkness was upon the face of the deep: and the Spirit of God moved upon the face of the waters. And God said, Let there be light: and there was light.\"\n",
    "sentence2=\"And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters. And God said, Let there be light: and there was light.\"\n",
    "\n",
    "aligner = iAligner()\n",
    "# alignment options /\n",
    "aligner.setOptions(1,0,1,0)\n",
    "viewer = Viewer()\n",
    "\n",
    "# run the alignment\n",
    "alignment = aligner.align(sentence1, sentence2)\n",
    "\n",
    "# view the alignment results in html table\n",
    "html=viewer.alignmentToText(alignment)\n",
    "html+=viewer.alignmentToHtmlCode(alignment)\n",
    "viewer.exportHtml(html,\"outputExample1.html\") #\"<br>\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'the', 'sentence2': 'the', 'relation': 'Aligned-complete'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"ialigner_output/outputExample1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x106c5fa90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"ialigner_output/outputExample1.html\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cite_corpus_reader.reader' from '../cite_corpus_reader/reader.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cite_corpus_reader import reader\n",
    "\n",
    "from importlib import reload\n",
    "reload(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cite_corpus_reader.reader import CapitainCorpusReader, AncientGreekPunktVar\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
